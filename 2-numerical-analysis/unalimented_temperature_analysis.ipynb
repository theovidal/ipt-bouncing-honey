{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data analysis - Unalimented setup with varying temperature\n",
    "\n",
    "This notebook uses code developed in the previous experiments to make data from a large collection of recordings.\n",
    "\n",
    "Setup characteristics:\n",
    "\n",
    "![Experimental setup](../docs/experimental-setup-spoon.png)"
   ],
   "id": "b38a728549e50977"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import libraries",
   "id": "8a7677b62c9ba680"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T18:18:46.712227Z",
     "start_time": "2025-02-02T18:18:44.102572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px"
   ],
   "id": "ba2c6d156d389172",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/theovld/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Open and parse data",
   "id": "aabfd53f9c43a74f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Merging all files",
   "id": "ef876f32394041f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This is only necessary once, when the data is spread out in multiple files (so, at the output of the [MATLAB program](../1-video-treatment)",
   "id": "de0881fa64a3d24d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T18:18:46.717459Z",
     "start_time": "2025-02-02T18:18:46.714415Z"
    }
   },
   "cell_type": "code",
   "source": "folder_path = 'results/26.11.not_filled'",
   "id": "939f8dde87214061",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_files = os.listdir(folder_path)\n",
    "\n",
    "def create_df(pattern, name, data=None):\n",
    "    \"\"\"\n",
    "        Utility function to create a dataframe out of sparse files\n",
    "        :param pattern regexp corresponding to files to gather\n",
    "        :param name the name of the merged file\n",
    "        :param data if set, the parameter should be a dataframe containing at least columns name, temperature, beginning - This is usually the \"information\" dataframe containing all video meta\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "\n",
    "    files = [f for f in all_files if pattern.search(f)]\n",
    "\n",
    "    for i, file in enumerate(files):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        filename = file[:12]\n",
    "        df['filename'] = filename\n",
    "        if data is not None:\n",
    "            info = data[data['name'] == filename].iloc[0]\n",
    "            df.drop(df[df.time < info.beginning].index, inplace=True)\n",
    "            df['temperature'] = info.temperature\n",
    "        dfs.append(df)\n",
    "\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    df.to_csv(os.path.join(folder_path, f'{name}.csv'), index=False)"
   ],
   "id": "81c336032ecaca75",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "info_pattern = re.compile(r'IMG_\\d{4}.avi.csv')\n",
    "\n",
    "create_df(info_pattern, 'info')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T18:18:47.919875Z",
     "start_time": "2025-02-02T18:18:47.875334Z"
    }
   },
   "cell_type": "code",
   "source": "info_df = pd.read_csv(f'{folder_path}/info.csv')",
   "id": "79ecc97a4f4aa03c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_pattern = re.compile(r'IMG_\\d{4}.avi.\\d{4}-\\d{2}-\\d{2}_\\d{2}-\\d{2}-\\d{2}.csv')\n",
    "\n",
    "create_df(data_pattern, 'data', info_df)"
   ],
   "id": "fe26ead288d9643e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T18:18:49.652882Z",
     "start_time": "2025-02-02T18:18:49.528922Z"
    }
   },
   "cell_type": "code",
   "source": "data_df = pd.read_csv(f'{folder_path}/data.csv', usecols=['frame','time','area','tip_y','filename','temperature'])",
   "id": "e188a4eab0f08110",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data types\n",
    "\n",
    "Temperature is a controlled parameter of our experiments"
   ],
   "id": "e08eb413c5df3d94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T18:18:52.360016Z",
     "start_time": "2025-02-02T18:18:52.255953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "info_df['temperature'] = info_df['temperature'].astype(str).astype('category')\n",
    "info_df.sort_values(by='temperature', ascending=True, inplace=True)\n",
    "\n",
    "data_df['temperature'] = data_df['temperature'].astype(str).astype('category')\n",
    "data_df.sort_values(['temperature', 'frame'], ascending=[True, True], inplace=True)"
   ],
   "id": "61c2323ef434e501",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Log-time, log-frame",
   "id": "c9c50668061d3094"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T18:18:52.536179Z",
     "start_time": "2025-02-02T18:18:52.530007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_df['log_frame'] = np.log(data_df['frame'])\n",
    "data_df['log_time'] = np.log(data_df['time'])"
   ],
   "id": "3f15f4134125fc6b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Converting area to cm²\n",
    "\n",
    "139px = 6mm\n",
    "So, 1px = 0,6/139 width and length, we square to get the area"
   ],
   "id": "b1c164aeafb3c7a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T18:18:52.607130Z",
     "start_time": "2025-02-02T18:18:52.596871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "px_to_cm = (0.6 / 139)\n",
    "\n",
    "data_df['area_px'] = data_df['area'].copy()\n",
    "data_df['area'] = data_df['area'] * px_to_cm**2\n",
    "data_df['tip_y_px'] = data_df['tip_y'].copy()\n",
    "data_df['tip_y'] = data_df['tip_y'] * px_to_cm"
   ],
   "id": "9ab11e469cfa6103",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Smoothing\n",
    "\n",
    "As the smoothing is quite severe, some anomalous values can appear at the edges. For that, we fill the last rows with a constant value"
   ],
   "id": "6e095013ca54b112"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T18:18:56.953728Z",
     "start_time": "2025-02-02T18:18:56.793700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.signal import savgol_filter\n",
    "\n",
    "for column in ['area', 'area_px', 'tip_y', 'tip_y_px']:\n",
    "    column_smooth = f'{column}_smooth'\n",
    "    data_df[column_smooth] = savgol_filter(data_df[column], window_length=12, polyorder=3, mode='mirror')\n",
    "\n",
    "    def fill_last_10_rows(g):\n",
    "        # Check if the group has more than 10 rows\n",
    "        if len(g) > 10:\n",
    "            # Get the value before the last 10 rows\n",
    "            last_valid_value = g.iloc[-11][column_smooth]\n",
    "            # Assign this value to the last 10 rows\n",
    "            g.iloc[-10:, g.columns.get_loc(column_smooth)] = last_valid_value\n",
    "        return g\n",
    "    \n",
    "    data_df = data_df.groupby('temperature', group_keys=False).apply(fill_last_10_rows)"
   ],
   "id": "e210d1d2ed28526a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29426/950131844.py:16: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data_df = data_df.groupby('temperature', group_keys=False).apply(fill_last_10_rows)\n",
      "/tmp/ipykernel_29426/950131844.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  data_df = data_df.groupby('temperature', group_keys=False).apply(fill_last_10_rows)\n",
      "/tmp/ipykernel_29426/950131844.py:16: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data_df = data_df.groupby('temperature', group_keys=False).apply(fill_last_10_rows)\n",
      "/tmp/ipykernel_29426/950131844.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  data_df = data_df.groupby('temperature', group_keys=False).apply(fill_last_10_rows)\n",
      "/tmp/ipykernel_29426/950131844.py:16: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data_df = data_df.groupby('temperature', group_keys=False).apply(fill_last_10_rows)\n",
      "/tmp/ipykernel_29426/950131844.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  data_df = data_df.groupby('temperature', group_keys=False).apply(fill_last_10_rows)\n",
      "/tmp/ipykernel_29426/950131844.py:16: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data_df = data_df.groupby('temperature', group_keys=False).apply(fill_last_10_rows)\n",
      "/tmp/ipykernel_29426/950131844.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  data_df = data_df.groupby('temperature', group_keys=False).apply(fill_last_10_rows)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Definition of code utilities",
   "id": "12f235ca5b839359"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Unique color palette for graphs, difference by temperature",
   "id": "de67d69bd26208d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T18:19:53.097103Z",
     "start_time": "2025-02-02T18:19:53.092710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dark24_colors = plotly.colors.qualitative.Dark24\n",
    "color_scale = px.colors.qualitative.Dark24\n",
    "\n",
    "temperatures = data_df['temperature'].unique()\n",
    "temp_to_color = {t: color_scale[i % len(color_scale)] for i, t in enumerate(temperatures)}\n",
    "\n",
    "def get_color(index):\n",
    "    return color_scale[index % len(color_scale)]"
   ],
   "id": "191f6bd61f7a5135",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create projector-friendly graphs",
   "id": "c62fa301b28f6744"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T18:19:54.373935Z",
     "start_time": "2025-02-02T18:19:54.365323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def style_for_projector(fig, monochrome=False, font_size=1, line_width=3, marker_size=10, width=None, height=None, log_x=False, log_y=False):\n",
    "    \"\"\"Applies projector-friendly styling to an existing plotly figure\"\"\"\n",
    "\n",
    "    fig.update_layout(\n",
    "        template=\"plotly_white\",\n",
    "        title=dict(\n",
    "            font=dict(size=24*font_size, color='black')\n",
    "        ),\n",
    "        width=width,\n",
    "        height=height,\n",
    "        plot_bgcolor='white',\n",
    "        paper_bgcolor='white',\n",
    "        margin=dict(t=100, b=100, l=100, r=50)\n",
    "    )\n",
    "    \n",
    "    if line_width is not None:\n",
    "        fig.update_traces(\n",
    "            line_width=line_width,\n",
    "            marker_size=marker_size,\n",
    "        )\n",
    "\n",
    "    if monochrome:\n",
    "        fig.update_traces(line_color='black', marker_color='black')\n",
    "    \n",
    "    fig.update_xaxes(\n",
    "        title=dict(font=dict(size=20*font_size)),\n",
    "        tickfont=dict(size=16*font_size*0.75),\n",
    "        showgrid=True,\n",
    "        gridcolor='lightgray',\n",
    "        nticks=6,\n",
    "        color='black',\n",
    "        minor=dict(ticks='inside', ticklen=6, showgrid=True)\n",
    "    )\n",
    "    \n",
    "    if log_x:\n",
    "        fig.update_xaxes(type='log')\n",
    "    else:\n",
    "        fig.update_xaxes(exponentformat='power', showexponent='last')\n",
    "    \n",
    "    fig.update_yaxes(title=dict(font=dict(size=20*font_size)),\n",
    "        tickfont=dict(size=16*font_size*0.75),\n",
    "        showgrid=True,\n",
    "        gridcolor='lightgray',\n",
    "        nticks=6,\n",
    "        color='black',\n",
    "        minor=dict(ticks='inside', ticklen=6, showgrid=True)\n",
    "    )\n",
    "\n",
    "    if log_y:\n",
    "        fig.update_yaxes(type='log')\n",
    "    else:\n",
    "        fig.update_yaxes(exponentformat='power', showexponent='last')\n",
    "\n",
    "    return fig"
   ],
   "id": "ee54f2ad1facc81c",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Individual analysis",
   "id": "d2204c2ed45e3b41"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Static area plot",
   "id": "96bc0dcd80b05c94"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = px.line(data_df, x='time', y='area', color='temperature', log_x=True)\n",
    "fig.update_layout(xaxis_title='Time (s)', yaxis_title='Area (cm^2)')"
   ],
   "id": "999e33114751951",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "video_name = 'IMG_0808.avi'\n",
    "\n",
    "fig = px.line(data_df[(data_df['filename'] == video_name)], x='time', y='area')\n",
    "fig = style_for_projector(fig, monochrome=True, font_size=2.5, width=1500)\n",
    "fig.show()"
   ],
   "id": "7b6e02ec9511f86a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's plot on a semi-log scale on time scale. We don't use log scale for area as we don't have a full decade ",
   "id": "63fa9499d2cc6c17"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = px.line(data_df[(data_df['filename'] == video_name)], x='time', y='area')\n",
    "fig = style_for_projector(fig, monochrome=True, font_size=2.5, width=1500, log_x=True)\n",
    "fig.update_xaxes(range=[math.log10(3), 2])\n",
    "fig.show()"
   ],
   "id": "e6177069a294b2a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = px.line(data_df[(data_df['filename'] == video_name)], x='time', y='area_smooth')\n",
    "fig = style_for_projector(fig, monochrome=True, font_size=2.5, width=1500, log_x=True)\n",
    "fig.update_xaxes(range=[math.log10(13.4), 2])\n",
    "fig.show()"
   ],
   "id": "8d2dd80cc721d2c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tip position and breakup length",
   "id": "4f990f08d27cde09"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_df['tip_y_cm'] = data_df['tip_y'] * px_to_cm",
   "id": "b2155a6fabacdf53",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "px.line(data_df[(data_df['filename'] == video_name)], x='time', y='tip_y_cm', labels={'x': 'Time (s)', 'y': 'Smoothed Area (cm²)'})",
   "id": "28d54b1fa36c852d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tool: create an animated side-by-side plot and video",
   "id": "a544933fc9df7b00"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from matplotlib.animation import FuncAnimation, FFMpegWriter\n",
    "\n",
    "start_time = 60.\n",
    "end_time = 66.\n",
    "\n",
    "# Set your desired frames per second\n",
    "fps = info_df[info_df['filename'] == video_name].framerate.iloc[0]\n",
    "\n",
    "df = data_df[(data_df['filename'] == video_name) & (data_df['time'] >= start_time) & (data_df['time'] <= end_time)]\n",
    "\n",
    "# Create the figure and axis\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "line, = ax.plot([], [], lw=2)  # an empty line to update later\n",
    "\n",
    "# Set axis labels and limits if desired\n",
    "ax.set_xlim(df['time'].min(), df['time'].max())\n",
    "ax.set_ylim(df['area'].min() - 0.1, df['area'].max() + 0.1)\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Area (#{pixels})')\n",
    "ax.set_title('Animated Line Plot')\n",
    "\n",
    "# Initialization function: clear the line data\n",
    "def init():\n",
    "    line.set_data([], [])\n",
    "    return line,\n",
    "\n",
    "# Update function: draw the line, up to the ith frame\n",
    "def update(frame):\n",
    "    # frame will go from 0 to len(df)-1\n",
    "    # Plot all data up to the current frame index\n",
    "    x_data = df['time'].iloc[:frame+1]\n",
    "    y_data = df['area'].iloc[:frame+1]\n",
    "    line.set_data(x_data, y_data)\n",
    "\n",
    "    return line,\n",
    "\n",
    "# Create the animation\n",
    "anim = FuncAnimation(fig, update, frames=len(df), init_func=init, blit=True, interval=1000/fps)\n",
    "\n",
    "# Save the animation to a file\n",
    "# Make sure you have ffmpeg installed. You can change codec and bitrate as needed.\n",
    "writer = FFMpegWriter(fps=fps, codec='libx264', bitrate=1500)\n",
    "anim.save('line_animation.mp4', writer=writer)"
   ],
   "id": "d87a3e9eea260470",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "TODO:\n",
    "- Define a crop height afterward"
   ],
   "id": "bf507f21b495a3aa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Peaks analysis from Phase 3",
   "id": "a969a90fdf828f77"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Qualitative observations from videos\n",
    "\n",
    "- Plus la température est basse, plus les phases sont longues\n",
    "\n",
    "- La phase 3 devient difficile à distinguer, mais on la définit qualitativement comme une **phase d'oscillation régulières** (il ne faut pas que ça soit une simple coupure dans un flot régulier)\n",
    "- Sur les graphiques -> Point de départ = une grosse descente suivie de pics régulièrement espacés\n",
    "- En général, avant la phase 3, la courbe a beaucoup de bruit et est + droite ; après, comporte surtout des oscillations\n",
    "- Même avant que ça soit complètement coupé, les \"drops\" vont très souvent par pairs\n"
   ],
   "id": "e447e149a72f5cc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Parsing data for Phase 3\n",
    "\n",
    "- We isolate data points that concern phase 3, that were manually identified on the videos\n",
    "- We apply a strong smoothing on the area curve"
   ],
   "id": "69ae958be7691655"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T18:20:25.276717Z",
     "start_time": "2025-02-02T18:20:25.241702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "phase3_map = dict(zip(info_df['temperature'], info_df['oscillations_beginning']))\n",
    "phase3_df = data_df[data_df['time'] >= data_df['temperature'].map(phase3_map).astype('float')].copy()\n",
    "\n",
    "# Threshold: only detect maximas that are above a certain value (not to catch too small maximas, that are not \"drops\" in terms of our definition)\n",
    "mid_max = phase3_df.groupby('temperature')['area_px_smooth'].transform(lambda x: np.max(x) / 3)\n",
    "threshold_df = phase3_df[phase3_df['area_px_smooth'] > mid_max]"
   ],
   "id": "3665c2e76d2959b2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29426/1488171521.py:5: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  mid_max = phase3_df.groupby('temperature')['area_px_smooth'].transform(lambda x: np.max(x) / 3)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Finding absolute peaks\n",
    "\n",
    "First, we apply the function from scipy to identify all peaks in the signals"
   ],
   "id": "32d19b26b886ac70"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T18:20:26.532720Z",
     "start_time": "2025-02-02T18:20:26.525427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "peaks_i, _ = find_peaks(\n",
    "    threshold_df['area_px_smooth'],\n",
    "    prominence=2,\n",
    "    distance=15,  # One peak for at least 1 second (empirical value)\n",
    ")\n",
    "peaks_df = threshold_df.iloc[peaks_i].copy()\n",
    "\n",
    "peaks_df['temperature'] = peaks_df['temperature'].astype(str)\n",
    "peaks_df['peak_number'] = peaks_df.groupby('temperature').cumcount()"
   ],
   "id": "435b70d56008d66c",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Filtering to get peaks corresponding to drops\n",
    "\n",
    "Then, we filter peaks that are not \"real\", i.e. they do not stand enough to be considered a drop time (for instance, we don't want to catch the bounce after the drop)"
   ],
   "id": "84bb666619d4c46a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T18:20:28.207669Z",
     "start_time": "2025-02-02T18:20:27.052930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "time_window = 0.1\n",
    "min_threshold = 1e4 * px_to_cm**2\n",
    "\n",
    "def check_relative_height(temperature, time):\n",
    "    area = data_df[(data_df['time'] >= time - time_window) & (data_df['time'] <= time + time_window) & (data_df['temperature'] == temperature)]['area_smooth']\n",
    "    return area.max() - area.min() > min_threshold\n",
    "\n",
    "relative_height_valid = peaks_df.apply(\n",
    "    lambda row: check_relative_height(row['temperature'], row['time']), axis=1\n",
    ")\n",
    "\n",
    "valid_peaks_df = peaks_df[relative_height_valid].copy()\n",
    "valid_peaks_df['peak_number'] = valid_peaks_df.groupby('temperature').cumcount()"
   ],
   "id": "a10fa14f85f62c43",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finally, we plot everything on a figure to control that our filtering is correct:",
   "id": "ee21309c42335581"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T12:03:56.323070Z",
     "start_time": "2025-01-25T12:03:56.253745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fig = px.line(\n",
    "    phase3_df,\n",
    "    x='time',\n",
    "    y='area_smooth',\n",
    "    color='temperature',\n",
    "    color_discrete_sequence=color_scale\n",
    ")\n",
    "\n",
    "fig_scatter = px.scatter(\n",
    "    valid_peaks_df,\n",
    "    x='time',\n",
    "    y='area_smooth',\n",
    "    color='temperature',\n",
    "    color_discrete_sequence=color_scale\n",
    ")\n",
    "\n",
    "for trace in fig_scatter.data:\n",
    "    fig.add_trace(trace, row=1, col=1)\n",
    "\n",
    "style_for_projector(fig)\n",
    "fig.show()"
   ],
   "id": "a8a43a96cc61c61e",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'phase3_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m fig \u001B[38;5;241m=\u001B[39m px\u001B[38;5;241m.\u001B[39mline(\n\u001B[0;32m----> 2\u001B[0m     \u001B[43mphase3_df\u001B[49m,\n\u001B[1;32m      3\u001B[0m     x\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      4\u001B[0m     y\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124marea_smooth\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      5\u001B[0m     color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtemperature\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      6\u001B[0m     color_discrete_sequence\u001B[38;5;241m=\u001B[39mcolor_scale\n\u001B[1;32m      7\u001B[0m )\n\u001B[1;32m      9\u001B[0m fig_scatter \u001B[38;5;241m=\u001B[39m px\u001B[38;5;241m.\u001B[39mscatter(\n\u001B[1;32m     10\u001B[0m     valid_peaks_df,\n\u001B[1;32m     11\u001B[0m     x\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     14\u001B[0m     color_discrete_sequence\u001B[38;5;241m=\u001B[39mcolor_scale\n\u001B[1;32m     15\u001B[0m )\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m trace \u001B[38;5;129;01min\u001B[39;00m fig_scatter\u001B[38;5;241m.\u001B[39mdata:\n",
      "\u001B[0;31mNameError\u001B[0m: name 'phase3_df' is not defined"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Standalone peaks analysis\n",
    "\n",
    "Here we pick a particular temperature to study the characteristics of peaks from a same profile: time, shape, area..."
   ],
   "id": "481a3346f7539970"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Selecting the video to analyse",
   "id": "e9f891f2f35e428"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "standalone_filename = 'IMG_0808.avi'\n",
    "\n",
    "standalone_data_df = data_df[data_df['filename'] == standalone_filename].copy()\n",
    "standalone_peaks_df = valid_peaks_df[valid_peaks_df['filename'] == standalone_filename].copy()"
   ],
   "id": "e8d2ac3b7e3fe4c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Calculating data and plotting peaks together",
   "id": "d4f744431d4b87b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calculate_slope(x, y):\n",
    "  start_idx = np.where(y >= 0.2)[0][0]\n",
    "  x_start, y_start = x[start_idx], y[start_idx]\n",
    "\n",
    "  # Find the peak (maximum y value and its corresponding x value)\n",
    "  peak_idx = np.argmax(y)  # Index of maximum y value\n",
    "  x_peak, y_peak = x[peak_idx], y[peak_idx]\n",
    "  return (y_peak - y_start) / (x_peak - x_start)"
   ],
   "id": "bf07dd37a21f2740",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "right_range = 0.5\n",
    "left_range = 0.5\n",
    "\n",
    "normalization_y = 0.6\n",
    "\n",
    "N = len(standalone_peaks_df)\n",
    "n = np.arange(N)\n",
    "integrals = np.zeros(N)\n",
    "integrals_smooth = np.zeros(N)\n",
    "slopes = np.zeros(N)\n",
    "slopes_smooth = np.zeros(N)\n",
    "\n",
    "fig = make_subplots(rows=2, cols=1)\n",
    "\n",
    "for i, point in enumerate(standalone_peaks_df['time']):\n",
    "  # Data fetching\n",
    "  temp_df = standalone_data_df[(standalone_data_df['time'] >= point - right_range) & (standalone_data_df['time'] <= point + left_range)]\n",
    "  x = temp_df['time'].values - point\n",
    "  y = temp_df['area'].values\n",
    "  y = (y - np.min(y)) / (np.max(y) - np.min(y))\n",
    "\n",
    "  y_smooth = temp_df['area_smooth'].values\n",
    "  y_smooth = (y_smooth - np.min(y_smooth)) / (np.max(y_smooth) - np.min(y_smooth))\n",
    "\n",
    "  integrals[i] = np.trapz(y, x)\n",
    "  integrals_smooth[i] = np.trapz(y_smooth, x)\n",
    "  \n",
    "  slopes[i] = calculate_slope(x, y)\n",
    "  slopes_smooth[i] = calculate_slope(x, y_smooth)\n",
    "  \n",
    "  norm_point = x[y_smooth >= normalization_y][0]\n",
    "\n",
    "  fig.add_trace(go.Scatter(\n",
    "    x=x, y=y_smooth, mode='lines', name=f'Peak {i}', line=dict(\n",
    "      color=get_color(i),\n",
    "    ),\n",
    "  ), row=1, col=1)\n",
    "\n",
    "  fig.add_trace(go.Scatter(\n",
    "    x=x / (-norm_point), y=y_smooth, mode='lines', name=f'Peak {i} with x norm', line=dict(\n",
    "      color=get_color(i),\n",
    "    ),\n",
    "  ), row=2, col=1)\n",
    "\n",
    "style_for_projector(fig, font_size=2.5, width=1200, height=1000)\n",
    "fig.show()"
   ],
   "id": "f8b6f6c7395344b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Integrals relation",
   "id": "8ee112d609345e2e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "mask = (n != 10)\n",
    "mean = np.mean(integrals[mask])\n",
    "mean_smooth = np.mean(integrals_smooth[mask])\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=n, y=integrals, mode='markers', name='Un-smoothed', marker_color='red'\n",
    "))\n",
    "fig.add_hline(y=mean, line_color='red', name='Un-smoothed')\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=n, y=integrals_smooth, mode='markers', name='Smoothed', marker_color='blue'\n",
    "))\n",
    "fig.add_hline(y=mean_smooth, line_color='blue', name='Smoothed')\n",
    "\n",
    "style_for_projector(fig, font_size=2.5)\n",
    "fig.show()"
   ],
   "id": "fa18150b88f5f14a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Slopes relation",
   "id": "c4bbb0885f9c2be3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "px.scatter(slopes_smooth)",
   "id": "ebe8f3466a986e8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mask = (n != 10)\n",
    "\n",
    "# fit = np.poly1d(np.polyfit(n[mask], slopes[mask], 3))\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=n, y=slopes, name='Data', mode='markers', marker_color='black'\n",
    "))\n",
    "\n",
    "n_continuous = np.arange(0, N, 0.01)\n",
    "\n",
    "# fig.add_trace(go.Scatter(\n",
    "#     x=n_continuous, y=fit(n_continuous), name='Prediction', mode='lines', line_color='blue'\n",
    "# ))\n",
    "\n",
    "def f(x):\n",
    "    v = 1.2 * (x-4.6)\n",
    "    return 1 + 7.1*np.exp(v) / (1 + np.exp(v))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=n_continuous, y=f(n_continuous), name='Sigmoid', mode='lines', line_color='red'\n",
    "))\n",
    "\n",
    "style_for_projector(fig, monochrome=True, font_size=2.5)\n",
    "fig.show()"
   ],
   "id": "2f1b7301dce77741",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Joint peaks analysis",
   "id": "cbbe8e6986dbc2cd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Plotting stacked peak lines",
   "id": "c22e6e12d98a38e2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T18:30:16.669602Z",
     "start_time": "2025-02-02T18:30:13.154803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "delta = 0.5\n",
    "\n",
    "temperatures = data_df['temperature'].unique()\n",
    "for i, temperature in enumerate(temperatures):\n",
    "    fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "    for peak_num, peak_time in enumerate(valid_peaks_df.loc[valid_peaks_df['temperature'] == temperature, 'time']):\n",
    "        seg = phase3_df[(phase3_df['temperature'] == temperature) &\n",
    "                    (phase3_df['time'] >= peak_time - delta) &\n",
    "                    (phase3_df['time'] <= peak_time + delta)].copy()\n",
    "        \n",
    "        x = seg['time'].values - peak_time\n",
    "        y = seg['area_smooth'].values\n",
    "        y_norm = (y - y.min()) / (y.max() - y.min())\n",
    "        norm_point = x[y_norm >= 0.6][0]\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=x / (- norm_point),\n",
    "                y=y_norm,\n",
    "                mode='lines',\n",
    "                name=f\"Peak {peak_num} (Temp={temperature})\",\n",
    "                hovertemplate='Time: %{x}<br>Norm Area: %{y}<extra></extra>',\n",
    "                marker=dict(color=get_color(peak_num))\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    fig = style_for_projector(fig, font_size=2.5)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=600,\n",
    "        showlegend=False,\n",
    "        title=f'T={temperature}°C',\n",
    "        xaxis_title=\"Shifted t [s]\",\n",
    "        yaxis_title=\"Normalized A\"\n",
    "    )\n",
    "    \n",
    "    fig.write_image(f'{temperature}.png')"
   ],
   "id": "665970a45e4507ec",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Looking for the tricking time law",
   "id": "188b6a0b977dc046"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Performing the regression\n",
    "\n",
    "We use a linear regression on the logarithm of the time, in order to find an exponential law for the time."
   ],
   "id": "ea68d4bc6d346566"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T12:05:34.095153Z",
     "start_time": "2025-01-25T12:05:34.031850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "temperatures = valid_peaks_df['temperature'].unique()\n",
    "\n",
    "x_values = []\n",
    "y_values = []\n",
    "polys = []\n",
    "residuals = []\n",
    "\n",
    "for i, t in enumerate(temperatures):\n",
    "    # Filter for a single temperature\n",
    "    df_temp = valid_peaks_df[valid_peaks_df['temperature'] == t]\n",
    "\n",
    "    # Extract x and y for the polyfit\n",
    "    x = df_temp['peak_number'].values\n",
    "    y = df_temp['log_time'].values\n",
    "    \n",
    "    x_values.append(x)\n",
    "    y_values.append(y)\n",
    "\n",
    "    # Compute linear fit: np.polyfit returns coefficients [m, b] for a line m*x+b\n",
    "    z, residual, rank, singular_values, rcond = np.polyfit(x, y, 1, full=True)\n",
    "    polys.append(z)\n",
    "    residuals.append(residual)"
   ],
   "id": "e49f83afb100daab",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Results",
   "id": "e8673c98bab6445a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Joint area and predictions plot\n",
    "\n",
    "We plot on the dashboard everything for our peaks analysis, and the verification of laws."
   ],
   "id": "13650f1de0084b2d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "color_scale = px.colors.qualitative.Dark24\n",
    "temp_to_color = {t: color_scale[i % len(color_scale)] for i, t in enumerate(temperatures)}\n",
    "\n",
    "# Initialize a Plotly figure\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    specs=[[{\"colspan\": 2}, None],\n",
    "           [{\"colspan\": 2}, None]],\n",
    "    vertical_spacing=0.15,\n",
    "    subplot_titles=(\"Area vs Log-time\", \"Log-Time vs. Peak Number by Temperature\")\n",
    ")\n",
    "\n",
    "fig_scatter = px.scatter(\n",
    "    peaks_df,\n",
    "    x='log_time',\n",
    "    y='area_smooth',\n",
    "    color='temperature',\n",
    "    color_discrete_sequence=color_scale\n",
    ")\n",
    "\n",
    "# Create a line plot for the studied phase\n",
    "fig_lines = px.line(\n",
    "    phase3_df,\n",
    "    x='log_time',\n",
    "    y='area_smooth',\n",
    "    color='temperature',\n",
    "    color_discrete_sequence=color_scale\n",
    ")\n",
    "\n",
    "for trace in fig_scatter.data:\n",
    "    fig.add_trace(trace, row=1, col=1)\n",
    "\n",
    "# Add all line traces to the specified subplot\n",
    "for trace in fig_lines.data:\n",
    "    fig.add_trace(trace, row=1, col=1)\n",
    "\n",
    "for i, t in enumerate(temperatures):\n",
    "    x = x_values[i]\n",
    "    y = y_values[i]\n",
    "\n",
    "    # Generate a smooth line for plotting\n",
    "    x_line = np.linspace(min(x), max(x), 100)\n",
    "    y_line = np.polyval(polys[i], x_line)\n",
    "\n",
    "    # Add scatter points\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        mode='markers',\n",
    "        name=f'Data (T={t}°C)',\n",
    "        marker=dict(color=temp_to_color[t]),\n",
    "        legendgroup=str(t),  # Grouping so toggling one also toggles the other if desired\n",
    "        visible=True\n",
    "    ),  row=2, col=1)\n",
    "\n",
    "    # Add regression line\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_line,\n",
    "        y=y_line,\n",
    "        mode='lines',\n",
    "        name=f'Fit (T={t}°C)',\n",
    "        line=dict(color=temp_to_color[t]),\n",
    "        legendgroup=str(t),\n",
    "        visible=True\n",
    "    ),  row=2, col=1)\n",
    "\n",
    "\n",
    "style_for_projector(fig, line_width=None)\n",
    "fig.update_layout(\n",
    "    title='Log Time vs. Peak Number by Temperature',\n",
    "    legend_title='Temperature Data',\n",
    "\n",
    "    height=1000,\n",
    "\n",
    "    xaxis_title='Log-Time',\n",
    "    yaxis_title='Smoothed Area (cm²)',\n",
    "\n",
    "    xaxis2_title='Peak Number',\n",
    "    yaxis2_title='Log-Time',\n",
    ")\n",
    "\n",
    "fig.show()"
   ],
   "id": "2b0d883d69a113dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Temperature influence on parameters",
   "id": "cc5fb8dbc5df0677"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T12:09:47.187059Z",
     "start_time": "2025-01-25T12:09:46.403360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fig = make_subplots(rows=1,cols=2)\n",
    "\n",
    "slopes = [poly[0] for poly in polys]\n",
    "intercepts = [poly[1] for poly in polys]\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=temperatures, y=slopes, name='a', mode='markers', marker_color='black', showlegend=False),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=temperatures, y=np.exp(intercepts), name='t_0 = exp(b)', mode='markers', marker_color='black', showlegend=False),\n",
    "    row=1, col=2\n",
    ")\n",
    "style_for_projector(fig, monochrome=True, font_size=2, width=1200)\n",
    "fig.write_image('params.png')"
   ],
   "id": "f298842a4c12eabb",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Plotting a standalone law",
   "id": "1e7280d1158dbd97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "video_name = 'IMG_0808.avi'\n",
    "index = 13\n",
    "\n",
    "x = x_values[index]\n",
    "y = np.exp(y_values[index])\n",
    "y_line = np.exp(np.polyval(polys[index], x))\n",
    "\n",
    "fig = make_subplots(rows=1,cols=1)\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=x, y=y, mode='markers'),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=x, y=y_line, mode='lines'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.update_layout(xaxis_title='n', yaxis_title='t_n')\n",
    "style_for_projector(fig, monochrome=True, font_size=2.5)"
   ],
   "id": "29a7186e11d655ea",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
